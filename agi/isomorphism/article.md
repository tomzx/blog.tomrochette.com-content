---
title: Isomorphism
created: 2016-07-28
taxonomy:
  tag: [artificial-general-intelligence]
  status: in progress
---

## Context

## Learned in this study

## Things to explore
* One can use Levenstein distance on things other than strings themselves, as long as there is an isomorphism that can be put in place (letters <-> ids)
* Is it possible to exploit the internals of the brain to do operations we do pretty badly at (e.g. computing huge numbers extremely rapidly)?

# Overview
Isomorphisms are a valuable tool in our toolset. It allows us to discover parallels between different domains while using the terms and ideas from the source domain. Furthermore, it can be the source of new discoveries in a target domain as the ideas from the source domain are explored in this target domain.

A good example of this is the application of mathematics to artificial intelligence. One may think of the brain as being a huge function that receives as input sensory data and returns as output motor commands. The brain can also be thought of as being a huge matrix that can store data of various kinds. Or it might be an immense graph where all the node aren't really containing anything but where the edges between those links contain the critical information (see the field of neural networks).

Another similar example is to compare the brain with computers. The brain contains memory, like the computer. It also has various levels of memory (cache), such as short-term and long-term memory. The brain is like an extremely parallel computer (with many many cores). The computer also has various inputs, such as a mouse, keyboard, midi controller, webcam, microphone, network interface and so on. A computer is generally composed of modular components such as the motherboard, CPU, GPU, memory, storage disk, external interfaces (mouse, keyboard, audio, network, etc) and power supply. The brain can be thought of doing all these things at once, but it appears to be much more monolithic in this aspect.

By doing these sort of association, it is possible for us to apply concepts in one domain to the other, when applicable. For instance, one might ask what is the bandwidth of the brain? How much memory does it have? What is its processing frequency? How much power does it need? How many transistor-like components does it have? What kind of architecture is it using? Is there any sort of pipelining of operations being involved? What is the depth of this pipeline? What part uses the most power? Is it possible to extract modular components?

# See also

# References
