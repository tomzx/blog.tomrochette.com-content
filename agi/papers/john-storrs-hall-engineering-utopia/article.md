---
title: Engineering utopia
created: 2016-08-20
taxonomy:
  tag: [Artificial General Intelligence]
  status: finished
---

## Context

## Learned in this study

## Things to explore
* At what rate should an AGI spend its time on self-improvement and on working on tasks? (this is basically the question of what is the appropriate ratio of time to dedicate as to not spend all your time self-improving, thus not using what you're improving vs working on tasks while you could improve yourself to do them faster)

# Overview
* If human intelligence is available for a dollar, why would anyone hire a human?
* If hyperhuman intelligence is available, why would you want a mere human to be in charge of anything important?
* Economic theory and history indicate that central control is extremely suboptimal for resource allocation and credit assignment. Some of the most promising AI architecture use internal markets or market-derived algorithms to address these problems

# See also

# References
