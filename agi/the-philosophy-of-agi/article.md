---
title: The Philosophy of AGI
created: 2017-05-26
taxonomy:
  category: [Artificial General Intelligence]
  status: in progress
---

## Context

## Learned in this study

## Things to explore
* Describe someone's position on various topic through a questionnaire, which in turn positions them in a multidimensional space (where each dimension is effectively the value given to a question in the questionnaire)

# Overview
Part of the reason I write this, is to understand how an AGI goes through the process of thinking about anything, and by doing so, is able to come up with a "superior" answer or position on any given topic. It is my hope that by doing so, it will put to light some practices that can be applied to human beings as well.

# Opinions
## Forming and changing opinion
* Opinions should be volatile, that is, it should be subject to change over time, but exist and be relied on at any given time
* The idea of volatility is that an AGI agent needs to be able to take decisions and proceed further into its thinking
* If at some point arguments are brought up that goes against what the agent believes in, these arguments should be evaluated against the existing framework that has been built
* When evaluating a position on a topic, it is important to consider the veracity of the facts presented
* It is also important to evaluate how often this opinion and its related facts would have useful to us compared to our existing position

## Opinions as Reinforcement Learning Problems
* In reinforcement learning, our objective is to maximize total reward
* We can see our beliefs as different states in a state space, where initially we have none, and through the acquisition of beliefs (actions), we transition from one state to another
* Reinforcement learning is about exploration and exploitation
	* Exploration of new states to determine their value (infrequent)
	* Exploitation of existing states, to benefit from the best discovered path so far (frequent)
* Contrary to reinforcement learning as implemented in computers, life cannot start from scratch in order to attempt a new path/sequence of actions to discover the value of the state it arrives at
	* However, it is possible to mentally simulate such given action sequence, either by starting from scratch or by starting from our current state
		* It is important to note that it is hard for human beings to evaluate another state without being biased by its current state. Doing so would require the ability to ignore/forget all of their existing preconceptions/decisions
* Similarly to reinforcement learning, given a metric (function) to determine whether a position is better than another position, it would be possible to order the states from lowest to highest total reward
	* One could say that the meaning of life in this case would be to discover and ascend this reward ladder
* Most human beings agree on a set of "values" which are important to a "good" life: happiness, health, comfort
	* See Maslow's hierarchy of needs

# See also

# References
* https://en.wikipedia.org/wiki/Computational_theory_of_mind
* https://www.quora.com/Is-there-something-like-computational-philosophy
* https://en.wikipedia.org/wiki/Digital_philosophy
* https://plato.stanford.edu/entries/computational-mind/