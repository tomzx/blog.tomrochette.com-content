---
title: Volodymyr Mnih - Human-level control through deep reinforcement learning (2015)
created: 2017-06-10
taxonomy:
  category: [Machine learning]
  status: finished
---

## Context

## Learned in this study

## Things to explore
* "The presence in the t-SNE embedding of overlapping clusters of points corresponding to the network representation of states experienced during human and agent play shows that the DQN agent also follows sequences of states similar to those found in human play. "
	* What is claimed here? That the game will transition the same way for both a human player and a DQN agent? That seems somewhat like a tautology...

# Overview

# Notes
* Two key ideas
	* First, we used a biologically inspired mechanism termed experience replay that randomizes over the data, thereby removing correlations in the observation sequence and smoothing over changes in the data distribution
	* Second, we used an iterative update that adjusts the action-values (Q) towards target values that are only periodically updated, thereby reducing correlations with the target
# See also

# See also
* [Playing Atari with Deep Reinforcement Learning](../volodymyr-mnih-playing-atari-with-deep-reinforcement-learning)

# References
* Mnih, Volodymyr, et al. "Human-level control through deep reinforcement learning." Nature 518.7540 (2015): 529-533.
